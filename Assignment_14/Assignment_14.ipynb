{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Tensorflow Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use one vGPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Aug 25 18:07:28 2019       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.67       Driver Version: 418.67       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  Off  | 00000000:62:00.0 Off |                    0 |\n",
      "| N/A   46C    P0    57W / 300W |      0MiB / 32480MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2...  Off  | 00000000:89:00.0 Off |                    0 |\n",
      "| N/A   45C    P0    55W / 300W |  31405MiB / 32480MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    1    129544      C   /root/anaconda3/bin/python                 31395MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CeQq2P-bjZxp"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load custom libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "cDiIO7ZZiDEm",
    "outputId": "77deaf85-4c39-4b0a-83aa-e9d05512e800"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'nn_utils'...\n",
      "remote: Enumerating objects: 104, done.\u001b[K\n",
      "remote: Counting objects: 100% (104/104), done.\u001b[K\n",
      "remote: Compressing objects: 100% (73/73), done.\u001b[K\n",
      "remote: Total 104 (delta 57), reused 74 (delta 29), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (104/104), 17.45 KiB | 0 bytes/s, done.\n",
      "Resolving deltas: 100% (57/57), done.\n",
      "Checking connectivity... done.\n"
     ]
    }
   ],
   "source": [
    "if tf.io.gfile.exists('./nn_utils'):\n",
    "  tf.io.gfile.rmtree('./nn_utils')\n",
    "!git clone https://github.com/ashxjain/nn_utils.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "z0DRPKl39290",
    "outputId": "5d069a8e-d124-4687-f5c3-6cb8f9a6c8c7"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import urllib\n",
    "import zipfile \n",
    "import tarfile\n",
    "from six.moves import urllib\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "# tf.keras imports\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Activation, Flatten, MaxPool2D, GlobalMaxPooling2D, Add, Lambda\n",
    "from tensorflow.keras.layers import BatchNormalization, AveragePooling2D, Input, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "# import for showing the confusion matrix\n",
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "import time, math\n",
    "\n",
    "from nn_utils import lr_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "9Ohk-wk-Ht9U",
    "outputId": "cfdfb23e-aeb1-4c2d-cda9-8e6aa11fea65"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.14.0'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate TFRecords\n",
    "\n",
    "* Generate 50000 Training dataset\n",
    "* Generate 10000 Validation dataset\n",
    "* Generate 50000 * 12 Augmented dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz and extract.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0825 18:07:54.321067 140465225697024 lazy_loader.py:50] \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "W0825 18:07:54.322296 140465225697024 deprecation.py:323] From <ipython-input-7-24289f2026fb>:39: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating /root/tfrecords/augmented_train_1.tfrecords...Done [50000 records]\n",
      "Generating /root/tfrecords/augmented_train_10.tfrecords...Done [50000 records]\n",
      "Generating /root/tfrecords/augmented_train_11.tfrecords...Done [50000 records]\n",
      "Generating /root/tfrecords/augmented_train_12.tfrecords...Done [50000 records]\n",
      "Generating /root/tfrecords/augmented_train_2.tfrecords...Done [50000 records]\n",
      "Generating /root/tfrecords/augmented_train_3.tfrecords...Done [50000 records]\n",
      "Generating /root/tfrecords/augmented_train_4.tfrecords...Done [50000 records]\n",
      "Generating /root/tfrecords/augmented_train_5.tfrecords...Done [50000 records]\n",
      "Generating /root/tfrecords/augmented_train_6.tfrecords...Done [50000 records]\n",
      "Generating /root/tfrecords/augmented_train_7.tfrecords...Done [50000 records]\n",
      "Generating /root/tfrecords/augmented_train_8.tfrecords...Done [50000 records]\n",
      "Generating /root/tfrecords/augmented_train_9.tfrecords...Done [50000 records]\n",
      "Generating /root/tfrecords/eval.tfrecords...Done [10000 records]\n",
      "Generating /root/tfrecords/train.tfrecords...Done [50000 records]\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Read CIFAR-10 data from pickled numpy arrays and writes TFRecords.\n",
    "Generates tf.train.Example protos and writes them to TFRecord files from the\n",
    "python version of the CIFAR-10 dataset downloaded from\n",
    "https://www.cs.toronto.edu/~kriz/cifar.html.\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import tarfile\n",
    "from six.moves import cPickle as pickle\n",
    "from six.moves import xrange\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.python.keras.utils.data_utils import Sequence, is_generator_or_sequence\n",
    "from albumentations import (\n",
    "    Compose, HorizontalFlip, RandomCrop, ToFloat, PadIfNeeded, Normalize, Cutout,Rotate\n",
    ")\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "CIFAR_FILENAME = 'cifar-10-python.tar.gz'\n",
    "CIFAR_DOWNLOAD_URL = 'https://www.cs.toronto.edu/~kriz/' + CIFAR_FILENAME\n",
    "CIFAR_LOCAL_FOLDER = 'cifar-10-batches-py'\n",
    "\n",
    "\n",
    "def download_and_extract(data_dir):\n",
    "  # download CIFAR-10 if not already downloaded.\n",
    "  tf.contrib.learn.datasets.base.maybe_download(CIFAR_FILENAME, data_dir,\n",
    "                                                CIFAR_DOWNLOAD_URL)\n",
    "  tarfile.open(os.path.join(data_dir, CIFAR_FILENAME),\n",
    "               'r:gz').extractall(data_dir)\n",
    "\n",
    "\n",
    "def _int64_feature(value):\n",
    "  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "\n",
    "def _bytes_feature(value):\n",
    "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "\n",
    "def _get_file_names():\n",
    "  \"\"\"Returns the file names expected to exist in the input_dir.\"\"\"\n",
    "  file_names = {}\n",
    "  file_names['train'] = ['data_batch_%d' % i for i in xrange(1, 6)]\n",
    "  for aug_idx in range(1, 13):\n",
    "      file_names['augmented_train_'+str(aug_idx)] = ['data_batch_%d' % i for i in xrange(1, 6)]  \n",
    "  file_names['eval'] = ['test_batch']\n",
    "  return file_names\n",
    "\n",
    "\n",
    "def read_pickle_from_file(filename):\n",
    "  with tf.gfile.Open(filename, 'rb') as f:\n",
    "    if sys.version_info >= (3, 0):\n",
    "      data_dict = pickle.load(f, encoding='bytes')\n",
    "    else:\n",
    "      data_dict = pickle.load(f)\n",
    "  return data_dict\n",
    "\n",
    "AUGMENTATIONS_TRAIN = Compose([\n",
    "    RandomCrop(32, 32),\n",
    "    HorizontalFlip(p=0.5),\n",
    "    Cutout(num_holes=1, p=1.0),\n",
    "])\n",
    "\n",
    "def preprocess_image(image_raw):\n",
    "    x_train = image_raw.reshape(10000, 32, 32, 3)\n",
    "\n",
    "    pad4 = lambda x: np.pad(x, [(0, 0), (4, 4), (4, 4), (0, 0)], mode='reflect')\n",
    "\n",
    "    x_train = pad4(x_train)\n",
    "    augmented_x = np.zeros((x_train.shape[0], 32, 32, 3))\n",
    "    for i in range(x_train.shape[0]):\n",
    "        augmented_x[i] = AUGMENTATIONS_TRAIN(image=x_train[i])[\"image\"]\n",
    "        \n",
    "    x_train = augmented_x.reshape(10000, 32*32*3).astype(np.int8)\n",
    "    return x_train\n",
    "    \n",
    "def convert_to_tfrecord(input_files, output_file, output_prefix):\n",
    "  \"\"\"Converts a file to TFRecords.\"\"\"\n",
    "  print('Generating %s...' % output_file, end='')\n",
    "  count = 0\n",
    "  with tf.python_io.TFRecordWriter(output_file) as record_writer:\n",
    "    for input_file in input_files:\n",
    "      data_dict = read_pickle_from_file(input_file)\n",
    "      data = data_dict[b'data']\n",
    "      labels = data_dict[b'labels']\n",
    "      num_entries_in_batch = len(labels)\n",
    "      if output_prefix.startswith(\"augmented_train\"):\n",
    "        data = preprocess_image(data)\n",
    "      for i in range(num_entries_in_batch):\n",
    "        example = tf.train.Example(features=tf.train.Features(\n",
    "            feature={\n",
    "                'image': _bytes_feature(data[i].tobytes()),\n",
    "                'label': _int64_feature(labels[i])\n",
    "            }))\n",
    "        record_writer.write(example.SerializeToString())\n",
    "      count += num_entries_in_batch\n",
    "  print('Done [%d records]' % (len(input_files)*num_entries_in_batch))\n",
    "\n",
    "def main(data_dir):\n",
    "  print('Download from {} and extract.'.format(CIFAR_DOWNLOAD_URL))\n",
    "  download_and_extract(data_dir)\n",
    "  file_names = _get_file_names()\n",
    "  input_dir = os.path.join(data_dir, CIFAR_LOCAL_FOLDER)\n",
    "  for mode, files in sorted(file_names.items(), key=lambda item: item[0]):\n",
    "    input_files = [os.path.join(input_dir, f) for f in files]\n",
    "    output_file = os.path.join(data_dir, mode + '.tfrecords')\n",
    "    try:\n",
    "      os.remove(output_file)\n",
    "    except OSError:\n",
    "      pass\n",
    "    # Convert to tf.train.Example and write the to TFRecords.\n",
    "    convert_to_tfrecord(input_files, output_file, mode)\n",
    "  print('Done!')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  main(\"/root/tfrecords\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model: DavidNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9mj6sUIhU009"
   },
   "outputs": [],
   "source": [
    "def init_pytorch(shape, dtype=tf.float32, partition_info=None):\n",
    "  fan = np.prod(shape[:-1])\n",
    "  bound = 1 / math.sqrt(fan)\n",
    "  return tf.random.uniform(shape, minval=-bound, maxval=bound, dtype=dtype)\n",
    "\n",
    "def ConvBN(c, x):\n",
    "  x = Conv2D(c, (3, 3), padding='same', kernel_regularizer=l2(weight_decay),kernel_initializer=init_pytorch, use_bias=False) (x)\n",
    "  x = (BatchNormalization(momentum=0.9)) (x)\n",
    "  x = (Activation('relu')) (x)\n",
    "  return x\n",
    "\n",
    "def layer(c, x):\n",
    "  x = ConvBN(c, x)\n",
    "  x = MaxPool2D (pool_size=(2, 2))(x)\n",
    "  x1 = ConvBN(c, x)\n",
    "  x1 = ConvBN(c, x1)\n",
    "  x1 = Add()([x1, x])\n",
    "  return x1\n",
    "\n",
    "def build(c=64, lr=0.02, tensor=None, out_tensor=None):\n",
    "  if tensor is not None:\n",
    "     _input = Input(tensor=tensor)\n",
    "  else:\n",
    "     _input = Input(shape=(32,32,3))\n",
    "  x = ConvBN (c, _input)\n",
    "  #Layer1\n",
    "  x = layer(c*2, x)\n",
    "  x = ConvBN(c*4, x)\n",
    "  x = MaxPool2D (pool_size=(2, 2))(x)\n",
    "  #Layer2\n",
    "  x = layer(c*8, x)\n",
    "  x = GlobalMaxPooling2D()(x)\n",
    "  x = Flatten()(x)\n",
    "  x = Dense(10, kernel_initializer=init_pytorch, kernel_regularizer=l2(weight_decay), use_bias=False) (x)\n",
    "  x = Lambda(lambda x: x *0.125)(x)\n",
    "  _output = Activation('softmax')(x)\n",
    "  model = Model(inputs=_input, outputs=_output)\n",
    "  \n",
    "  optimizer = SGD(lr=lr, momentum=0.9, nesterov=True)\n",
    "  if out_tensor is not None:\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'], target_tensors=[out_tensor])\n",
    "  else:\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper-Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "szqTyVzuJvFe"
   },
   "outputs": [],
   "source": [
    "nb_epoch = 24\n",
    "batch_size = 512\n",
    "weight_decay = 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize OneCycleLR Policy Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_lr=1\n",
    "lr_manager = lr_utils.OneCycleLR(\n",
    "    sl_epoch=5,\n",
    "    end_epoch=8,\n",
    "    max_lr=max_lr, min_lr=max_lr/5.0,\n",
    "    maximum_momentum=0.95,\n",
    "    verbose=True,\n",
    "    batch_size=batch_size,\n",
    "    steps_per_epoch=50000//batch_size\n",
    ")\n",
    "lr_manager.test_run(epochs=24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load TFRecords\n",
    "* In every step, load 256 images from training set and 256 from augmented set = 512 images per step\n",
    "* 1 epoch == 97 step == (256+256) * 97 images ~= 50000 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_HEIGHT = 32\n",
    "IMAGE_WIDTH = 32\n",
    "IMAGE_DEPTH = 3\n",
    "NUM_CLASSES = 10\n",
    "rgb_mean = tf.constant((0.4914, 0.4822, 0.4465), dtype=tf.float32)\n",
    "rgb_std = tf.constant((0.2470, 0.2435, 0.2616), dtype=tf.float32)\n",
    "\n",
    "def parse_record(serialized_example):\n",
    "    features = tf.parse_single_example(\n",
    "    serialized_example,\n",
    "    features={\n",
    "      'image': tf.FixedLenFeature([], tf.string),\n",
    "      'label': tf.FixedLenFeature([], tf.int64),\n",
    "    })\n",
    "\n",
    "    image = tf.decode_raw(features['image'], tf.uint8)\n",
    "    image.set_shape([IMAGE_DEPTH * IMAGE_HEIGHT * IMAGE_WIDTH])\n",
    "    image = tf.reshape(image, [IMAGE_DEPTH, IMAGE_HEIGHT, IMAGE_WIDTH])\n",
    "    image = tf.cast(tf.transpose(image, [1, 2, 0]), tf.float32) * (1. / 255.)\n",
    "\n",
    "    # TODO: Handle normalization for Augmented images as well\n",
    "    #image = tf.subtract(image, rgb_mean)\n",
    "    #image = tf.divide(image, rgb_std)\n",
    "\n",
    "    label = tf.cast(features['label'], tf.int32)\n",
    "    return image, label\n",
    "\n",
    "def fetch_dataset(filenames, batch_size, training=False):\n",
    "    if training:\n",
    "        files = tf.data.Dataset.from_tensor_slices(filenames)\n",
    "        dataset = files.interleave(lambda x: tf.data.TFRecordDataset(x), cycle_length=2, block_length=batch_size//2)\n",
    "    else:\n",
    "        dataset = tf.data.TFRecordDataset(filenames=filenames)\n",
    "\n",
    "    if training:\n",
    "      buffer_size = batch_size * 2 + 1\n",
    "      dataset = dataset.shuffle(buffer_size=buffer_size)\n",
    "\n",
    "    # Transformation\n",
    "    dataset = dataset.map(parse_record, num_parallel_calls=4)\n",
    "\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(2 * batch_size)\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize images from TFRecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_img(img, figsize=(2, 2)):\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    ax.grid(False)\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_xticklabels([])\n",
    "    ax.imshow(img)\n",
    "    plt.imshow(img)\n",
    "\n",
    "files = []\n",
    "for i in range(1,13):\n",
    "    files.append(\"/root/tfrecords/train.tfrecords\")\n",
    "    files.append(\"/root/tfrecords/augmented_train_\"+str(i)+\".tfrecords\")\n",
    "\n",
    "dataset = fetch_dataset(files, 2, False)\n",
    "cnt = 0\n",
    "for i in dataset:\n",
    "    cnt += 1\n",
    "    if cnt == 1 or cnt == 50000 or cnt == 50001:\n",
    "        for img in i[0]:\n",
    "            show_img(img)\n",
    "    if cnt == 50002:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VQWJ-urr99OC"
   },
   "outputs": [],
   "source": [
    "def train_model(max_lr =1, verbose=True):\n",
    "    if verbose:\n",
    "      verbose_val = 1\n",
    "    else:\n",
    "      verbose_val = 0\n",
    "    checkpoint = ModelCheckpoint(\"assignment_14_weights.hdf5\", monitor='val_acc', verbose=verbose_val, save_best_only=True, mode='max')\n",
    "\n",
    "\n",
    "    lr_manager = lr_utils.OneCycleLR(sl_epoch=5,\n",
    "                        end_epoch=8,\n",
    "                        max_lr=max_lr, min_lr=max_lr/5.0,\n",
    "                        maximum_momentum=0.95,\n",
    "                        verbose=verbose,\n",
    "                        batch_size=batch_size,\n",
    "                        steps_per_epoch=50000//batch_size)\n",
    "\n",
    "    files = []\n",
    "    for i in range(1,13):\n",
    "        files.append(\"/root/tfrecords/train.tfrecords\")\n",
    "        files.append(\"/root/tfrecords/augmented_train_\"+str(i)+\".tfrecords\")\n",
    "    train_data = fetch_dataset(files, batch_size, True)\n",
    "    val_data = fetch_dataset([\"/root/tfrecords/eval.tfrecords\"], batch_size)\n",
    "\n",
    "    callbacks=[lr_manager, checkpoint]\n",
    "\n",
    "    train_history = model.fit(\n",
    "      train_data,\n",
    "      epochs=nb_epoch, steps_per_epoch=50000//batch_size,\n",
    "      validation_data=val_data, validation_steps=10000//batch_size,\n",
    "      callbacks=callbacks)\n",
    "\n",
    "    return train_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Model Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "1K2vFfwJhz3n",
    "outputId": "c9df8861-9933-4724-c927-e8e0f6eae848",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/24\n",
      "96/97 [============================>.] - ETA: 0s - loss: 1.6306 - acc: 0.4276 - lr: 0.21501 - momentum: 0.93 \n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.53382, saving model to assignment_14_weights.hdf5\n",
      "97/97 [==============================] - 15s 154ms/step - loss: 1.6265 - acc: 0.4293 - val_loss: 1.3739 - val_acc: 0.5338\n",
      "Epoch 2/24\n",
      "96/97 [============================>.] - ETA: 0s - loss: 1.2074 - acc: 0.6042 - lr: 0.31101 - momentum: 0.91 \n",
      "\n",
      "Epoch 00002: val_acc improved from 0.53382 to 0.61246, saving model to assignment_14_weights.hdf5\n",
      "97/97 [==============================] - 8s 87ms/step - loss: 1.2064 - acc: 0.6047 - val_loss: 1.2613 - val_acc: 0.6125\n",
      "Epoch 3/24\n",
      "96/97 [============================>.] - ETA: 0s - loss: 1.0729 - acc: 0.6643 - lr: 0.40701 - momentum: 0.89 \n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.61246\n",
      "97/97 [==============================] - 8s 85ms/step - loss: 1.0724 - acc: 0.6648 - val_loss: 1.2863 - val_acc: 0.6031\n",
      "Epoch 4/24\n",
      "96/97 [============================>.] - ETA: 0s - loss: 1.0107 - acc: 0.6959 - lr: 0.50301 - momentum: 0.87 \n",
      "\n",
      "Epoch 00004: val_acc improved from 0.61246 to 0.72852, saving model to assignment_14_weights.hdf5\n",
      "97/97 [==============================] - 8s 87ms/step - loss: 1.0111 - acc: 0.6960 - val_loss: 0.9288 - val_acc: 0.7285\n",
      "Epoch 5/24\n",
      "96/97 [============================>.] - ETA: 0s - loss: 0.9382 - acc: 0.7298 - lr: 0.59901 - momentum: 0.85 \n",
      "\n",
      "Epoch 00005: val_acc improved from 0.72852 to 0.72944, saving model to assignment_14_weights.hdf5\n",
      "97/97 [==============================] - 8s 85ms/step - loss: 0.9371 - acc: 0.7301 - val_loss: 1.0210 - val_acc: 0.7294\n",
      "Epoch 6/24\n",
      "96/97 [============================>.] - ETA: 0s - loss: 0.8420 - acc: 0.7695 - lr: 0.55681 - momentum: 0.86 \n",
      "\n",
      "Epoch 00006: val_acc improved from 0.72944 to 0.77457, saving model to assignment_14_weights.hdf5\n",
      "97/97 [==============================] - 8s 85ms/step - loss: 0.8423 - acc: 0.7694 - val_loss: 0.8733 - val_acc: 0.7746\n",
      "Epoch 7/24\n",
      "96/97 [============================>.] - ETA: 0s - loss: 0.7868 - acc: 0.7909 - lr: 0.51318 - momentum: 0.87 \n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.77457\n",
      "97/97 [==============================] - 8s 84ms/step - loss: 0.7858 - acc: 0.7912 - val_loss: 0.9046 - val_acc: 0.7551\n",
      "Epoch 8/24\n",
      "96/97 [============================>.] - ETA: 0s - loss: 0.7470 - acc: 0.8071 - lr: 0.46954 - momentum: 0.88 \n",
      "\n",
      "Epoch 00008: val_acc improved from 0.77457 to 0.79544, saving model to assignment_14_weights.hdf5\n",
      "97/97 [==============================] - 8s 85ms/step - loss: 0.7463 - acc: 0.8075 - val_loss: 0.8439 - val_acc: 0.7954\n",
      "Epoch 9/24\n",
      "96/97 [============================>.] - ETA: 0s - loss: 0.7123 - acc: 0.8260 - lr: 0.42590 - momentum: 0.89 \n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.79544\n",
      "97/97 [==============================] - 8s 84ms/step - loss: 0.7121 - acc: 0.8260 - val_loss: 0.8494 - val_acc: 0.7887\n",
      "Epoch 10/24\n",
      "96/97 [============================>.] - ETA: 0s - loss: 0.6920 - acc: 0.8343 - lr: 0.38227 - momentum: 0.90 \n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.79544\n",
      "97/97 [==============================] - 8s 83ms/step - loss: 0.6919 - acc: 0.8342 - val_loss: 1.1878 - val_acc: 0.7132\n",
      "Epoch 11/24\n",
      "96/97 [============================>.] - ETA: 0s - loss: 0.6647 - acc: 0.8489 - lr: 0.33863 - momentum: 0.90 \n",
      "\n",
      "Epoch 00011: val_acc improved from 0.79544 to 0.83111, saving model to assignment_14_weights.hdf5\n",
      "97/97 [==============================] - 8s 85ms/step - loss: 0.6641 - acc: 0.8491 - val_loss: 0.7442 - val_acc: 0.8311\n",
      "Epoch 12/24\n",
      "96/97 [============================>.] - ETA: 0s - loss: 0.6465 - acc: 0.8564 - lr: 0.29500 - momentum: 0.91 \n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.83111\n",
      "97/97 [==============================] - 8s 82ms/step - loss: 0.6465 - acc: 0.8566 - val_loss: 0.7498 - val_acc: 0.8281\n",
      "Epoch 13/24\n",
      "96/97 [============================>.] - ETA: 0s - loss: 0.6237 - acc: 0.8643 - lr: 0.25136 - momentum: 0.92 \n",
      "\n",
      "Epoch 00013: val_acc improved from 0.83111 to 0.84745, saving model to assignment_14_weights.hdf5\n",
      "97/97 [==============================] - 8s 85ms/step - loss: 0.6245 - acc: 0.8641 - val_loss: 0.7038 - val_acc: 0.8475\n",
      "Epoch 14/24\n",
      "96/97 [============================>.] - ETA: 0s - loss: 0.6177 - acc: 0.8695 - lr: 0.20772 - momentum: 0.93 \n",
      "\n",
      "Epoch 00014: val_acc improved from 0.84745 to 0.84858, saving model to assignment_14_weights.hdf5\n",
      "97/97 [==============================] - 8s 83ms/step - loss: 0.6172 - acc: 0.8696 - val_loss: 0.7192 - val_acc: 0.8486\n",
      "Epoch 15/24\n",
      "96/97 [============================>.] - ETA: 0s - loss: 0.5870 - acc: 0.8817 - lr: 0.16409 - momentum: 0.94 \n",
      "\n",
      "Epoch 00015: val_acc improved from 0.84858 to 0.85485, saving model to assignment_14_weights.hdf5\n",
      "97/97 [==============================] - 8s 82ms/step - loss: 0.5874 - acc: 0.8816 - val_loss: 0.7025 - val_acc: 0.8549\n",
      "Epoch 16/24\n",
      "96/97 [============================>.] - ETA: 0s - loss: 0.5761 - acc: 0.8881 - lr: 0.12045 - momentum: 0.95 \n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.85485\n",
      "97/97 [==============================] - 8s 82ms/step - loss: 0.5757 - acc: 0.8884 - val_loss: 0.7007 - val_acc: 0.8537\n",
      "Epoch 17/24\n",
      "96/97 [============================>.] - ETA: 0s - loss: 0.5479 - acc: 0.8977"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "\n",
    "lr=0.6\n",
    "\n",
    "model = build(lr=lr)\n",
    "\n",
    "K.set_value(model.optimizer.decay, 0.0005 * batch_size)\n",
    "\n",
    "train_history = train_model(max_lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time taken by: Conv layers & BN layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "class TimeHistory(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "\n",
    "    def on_epoch_begin(self, batch, logs={}):\n",
    "        self.epoch_time_start = time.time()\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.times.append(time.time() - self.epoch_time_start)\n",
    "\n",
    "def get_average_layer_train_time(model, layer_prefix, epochs):\n",
    "\n",
    "    #Loop through each layer setting it Trainable and others as non trainable\n",
    "    time_callback = TimeHistory()\n",
    "    n_layers = 0\n",
    "    \n",
    "    #Setting all layers as non-Trainable\n",
    "    for i in range(len(model.layers)):\n",
    "        model.layers[i].trainable = False\n",
    "        if model.layers[i].name.startswith(layer_prefix):\n",
    "            model.layers[i].trainable = True\n",
    "            n_layers += 1\n",
    "\n",
    "    optimizer = SGD(lr=0.4, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    \n",
    "    files = []\n",
    "    for i in range(1,13):\n",
    "        files.append(\"/root/tfrecords/train.tfrecords\")\n",
    "        files.append(\"/root/tfrecords/augmented_train_\"+str(i)+\".tfrecords\")\n",
    "    train_data = fetch_dataset(files, batch_size, True)\n",
    "\n",
    "    #Fit on a small number of epochs with callback that records time for each epoch\n",
    "    model.fit(\n",
    "        train_data,\n",
    "        epochs=epochs,\n",
    "        steps_per_epoch=50000//batch_size,\n",
    "        callbacks=[time_callback]\n",
    "    )\n",
    "\n",
    "    #Print average of the time for each layer\n",
    "    print(\">>\", n_layers, layer_prefix, \": Approx (avg) train time for \", epochs, \"epochs =\", np.average(time_callback.times))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "97/97 [==============================] - 3s 32ms/step - loss: 2.4127 - acc: 0.0986\n",
      "Epoch 2/5\n",
      "97/97 [==============================] - 3s 34ms/step - loss: 2.4161 - acc: 0.0994\n",
      "Epoch 3/5\n",
      "97/97 [==============================] - 3s 34ms/step - loss: 2.4133 - acc: 0.0983\n",
      "Epoch 4/5\n",
      "97/97 [==============================] - 3s 34ms/step - loss: 2.4160 - acc: 0.0997\n",
      "Epoch 5/5\n",
      "97/97 [==============================] - 3s 34ms/step - loss: 2.4133 - acc: 0.0984\n",
      ">> 0 no-layers : Approx (avg) train time for  5 epochs = 3.260294485092163\n",
      "Epoch 1/5\n",
      "97/97 [==============================] - 12s 124ms/step - loss: 1.6657 - acc: 0.4396\n",
      "Epoch 2/5\n",
      "97/97 [==============================] - 7s 75ms/step - loss: 1.2820 - acc: 0.6022\n",
      "Epoch 3/5\n",
      "97/97 [==============================] - 7s 75ms/step - loss: 1.1371 - acc: 0.6604\n",
      "Epoch 4/5\n",
      "97/97 [==============================] - 7s 75ms/step - loss: 1.0578 - acc: 0.6962\n",
      "Epoch 5/5\n",
      "97/97 [==============================] - 7s 75ms/step - loss: 0.9920 - acc: 0.7226\n",
      ">> 8 conv : Approx (avg) train time for  5 epochs = 8.241568517684936\n",
      "Epoch 1/5\n",
      "97/97 [==============================] - 11s 115ms/step - loss: 0.8831 - acc: 0.7592\n",
      "Epoch 2/5\n",
      "97/97 [==============================] - 6s 59ms/step - loss: 0.8526 - acc: 0.7581\n",
      "Epoch 3/5\n",
      "97/97 [==============================] - 6s 60ms/step - loss: 0.7823 - acc: 0.7811\n",
      "Epoch 4/5\n",
      "97/97 [==============================] - 6s 60ms/step - loss: 0.8021 - acc: 0.7693\n",
      "Epoch 5/5\n",
      "97/97 [==============================] - 6s 60ms/step - loss: 0.7264 - acc: 0.7985\n",
      ">> 8 batch_normalization : Approx (avg) train time for  5 epochs = 6.861351013183594\n"
     ]
    }
   ],
   "source": [
    "model = build()\n",
    "get_average_layer_train_time(model, \"no-layers\", 5)\n",
    "get_average_layer_train_time(model, \"conv\", 5)\n",
    "get_average_layer_train_time(model, \"batch_normalization\", 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* No Layers = 3s\n",
    "* All Conv Layers = 8-3 = 5s\n",
    "* All BN Layers = 7-3 = 4s"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Assignment_14_93890.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
