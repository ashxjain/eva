{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 131
    },
    "colab_type": "code",
    "id": "K70hAckqg0EA",
    "outputId": "455bc2b6-9496-4c74-d2b3-bffb604e38da"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'nn_utils'...\n",
      "remote: Enumerating objects: 137, done.\u001b[K\n",
      "remote: Counting objects: 100% (137/137), done.\u001b[K\n",
      "remote: Compressing objects: 100% (91/91), done.\u001b[K\n",
      "remote: Total 137 (delta 73), reused 98 (delta 36), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (137/137), 22.61 KiB | 0 bytes/s, done.\n",
      "Resolving deltas: 100% (73/73), done.\n",
      "Checking connectivity... done.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "# This part will prevent tensorflow to allocate all the avaliable GPU Memory\n",
    "# backend\n",
    "# Don't pre-allocate memory; allocate as-needed\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "# Create a session with the above options specified.\n",
    "K.set_session(tf.Session(config=config))\n",
    "\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Input, AveragePooling2D, Activation\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Download & Import my custom library utilities\n",
    "if tf.io.gfile.exists('./nn_utils'):\n",
    "  tf.io.gfile.rmtree('./nn_utils')\n",
    "!git clone https://github.com/ashxjain/nn_utils.git\n",
    "  \n",
    "import nn_utils.data.tfrecords as tfrecords\n",
    "import nn_utils.visualize as vis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Single Tesla V100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Sep  1 10:04:05 2019       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.67       Driver Version: 418.67       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  Off  | 00000000:62:00.0 Off |                    0 |\n",
      "| N/A   46C    P0    57W / 300W |    317MiB / 32480MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2...  Off  | 00000000:89:00.0 Off |                    0 |\n",
      "| N/A   46C    P0    56W / 300W |    317MiB / 32480MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0      8085      C   /root/anaconda3/bin/python                   307MiB |\n",
      "|    1      8085      C   /root/anaconda3/bin/python                   307MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dsO_yGxcg5D8"
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 50\n",
    "l = 40\n",
    "num_filter = 12\n",
    "compression = 0.5\n",
    "dropout_rate = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create TFRecords for CIFAR-10 Dataset in CWD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 32
    },
    "colab_type": "code",
    "id": "6tWB88sLDNgN",
    "outputId": "c856f7a7-bc9d-4b22-c8bd-5be0d348d0d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz and extract.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0901 10:04:10.546620 140214027335424 lazy_loader.py:50] \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "W0901 10:04:10.547948 140214027335424 deprecation.py:323] From /root/Ashish/nn_utils/data/tfrecords.py:26: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "W0901 10:04:10.549075 140214027335424 deprecation.py:323] From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded cifar-10-python.tar.gz 170498071 bytes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0901 10:04:15.234030 140214027335424 deprecation_wrapper.py:119] From /root/Ashish/nn_utils/data/tfrecords.py:54: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
      "\n",
      "W0901 10:04:15.235785 140214027335424 deprecation_wrapper.py:119] From /root/Ashish/nn_utils/data/tfrecords.py:43: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating ./eval.tfrecords...Done [10000 records]\n",
      "Generating ./train.tfrecords...Done [50000 records]\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "tfrecords.create(\"cifar10\", \"./\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load TFRecords & Augment the loaded images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 361
    },
    "colab_type": "code",
    "id": "r7xYudt41uq1",
    "outputId": "51d28be9-60fb-4da9-8d64-a55d5f8d496a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0901 10:05:32.302821 140214027335424 deprecation.py:323] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/image_ops_impl.py:1514: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "W0901 10:05:32.372162 140214027335424 deprecation.py:323] From <ipython-input-5-6ebf02fe136e>:27: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.\n",
      "W0901 10:05:32.616547 140214027335424 image.py:656] Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "W0901 10:05:32.619488 140214027335424 image.py:656] Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "W0901 10:05:32.784853 140214027335424 image.py:656] Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "W0901 10:05:32.787804 140214027335424 image.py:656] Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess(img, img_shape, training):\n",
    "    img = img * (1. / 255.)\n",
    "    img_height, img_width, img_depth = img_shape\n",
    "    if training:\n",
    "        # Resize the image to add four extra pixels on each side.\n",
    "        img = tf.image.resize_image_with_crop_or_pad(\n",
    "            img,\n",
    "            img_height + 8,\n",
    "            img_width + 8\n",
    "        )\n",
    "\n",
    "        # Randomly crop a [_height, _width] section of the image.\n",
    "        img = tf.random_crop(img, img_shape)\n",
    "\n",
    "        # Randomly flip the image horizontally.\n",
    "        img = tf.image.random_flip_left_right(img)\n",
    "\n",
    "     # Subtract off the mean and divide by the variance of the pixels.\n",
    "    img = tf.image.per_image_standardization(img)\n",
    "    return img\n",
    "\n",
    "\n",
    "train_dataset = tfrecords.load(\"cifar10\", [\"./train.tfrecords\"], batch_size, preprocess, training=True)\n",
    "test_dataset = tfrecords.load(\"cifar10\", [\"./eval.tfrecords\"], batch_size, preprocess, training=False)\n",
    "\n",
    "# Visualize TFRecord Dataset\n",
    "iter = train_dataset.make_initializable_iterator()\n",
    "el = iter.get_next()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(iter.initializer)\n",
    "    img, lab = sess.run(el)\n",
    "    vis.show_image(img[0])\n",
    "\n",
    "iter = test_dataset.make_initializable_iterator()\n",
    "el = iter.get_next()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(iter.initializer)\n",
    "    img, lab = sess.run(el)\n",
    "    vis.show_image(img[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define DenseNet Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ee-sge5Kg7vr"
   },
   "outputs": [],
   "source": [
    "# Dense Block\n",
    "def add_denseblock(input, num_filter = 12, dropout_rate = 0.2):\n",
    "    temp = input\n",
    "    for _ in range(l):\n",
    "        BatchNorm = BatchNormalization()(temp)\n",
    "        relu = Activation('relu')(BatchNorm)\n",
    "        Conv2D_3_3 = Conv2D(int(num_filter), (3,3), use_bias=False ,padding='same')(relu)\n",
    "        if dropout_rate>0:\n",
    "            Conv2D_3_3 = Dropout(dropout_rate)(Conv2D_3_3)\n",
    "        concat = Concatenate(axis=-1)([temp, Conv2D_3_3])\n",
    "        \n",
    "        temp = concat\n",
    "        \n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OOP6IPsGhBwb"
   },
   "outputs": [],
   "source": [
    "def add_transition(input, num_filter = 12, dropout_rate = 0.2):\n",
    "    global compression\n",
    "    BatchNorm = BatchNormalization()(input)\n",
    "    relu = Activation('relu')(BatchNorm)\n",
    "    Conv2D_BottleNeck = Conv2D(int(num_filter*compression), (1,1), use_bias=False ,padding='same')(relu)\n",
    "    if dropout_rate>0:\n",
    "        Conv2D_BottleNeck = Dropout(dropout_rate)(Conv2D_BottleNeck)\n",
    "    avg = AveragePooling2D(pool_size=(2,2))(Conv2D_BottleNeck)\n",
    "    \n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0RaKFpubhDIC"
   },
   "outputs": [],
   "source": [
    "def output_layer(input):\n",
    "    BatchNorm = BatchNormalization()(input)\n",
    "    #relu = Activation('relu')(BatchNorm)\n",
    "    AvgPooling = AveragePooling2D(pool_size=(2,2))(BatchNorm)\n",
    "    flat = Flatten()(AvgPooling)\n",
    "    output = Dense(num_classes, activation='softmax')(flat)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "anPCpQWhhGb7",
    "outputId": "84522b84-e801-47b5-dee1-09da7db1aaf0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0901 10:05:38.291969 140214027335424 deprecation.py:506] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "num_filter = 12\n",
    "dropout_rate = 0.2\n",
    "l = 12\n",
    "\n",
    "input = Input(shape=(32, 32, 3))\n",
    "First_Conv2D = Conv2D(num_filter, (3,3), use_bias=False ,padding='same')(input)\n",
    "\n",
    "First_Block = add_denseblock(First_Conv2D, num_filter, dropout_rate)\n",
    "First_Transition = add_transition(First_Block, num_filter, dropout_rate)\n",
    "\n",
    "Second_Block = add_denseblock(First_Transition, num_filter, dropout_rate)\n",
    "Second_Transition = add_transition(Second_Block, num_filter, dropout_rate)\n",
    "\n",
    "Third_Block = add_denseblock(Second_Transition, num_filter, dropout_rate)\n",
    "Third_Transition = add_transition(Third_Block, num_filter, dropout_rate)\n",
    "\n",
    "Last_Block = add_denseblock(Third_Transition,  num_filter, dropout_rate)\n",
    "output = output_layer(Last_Block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "1kFh7pdxhNtT",
    "outputId": "d250446d-f926-46ab-9fbf-4b6ec7899134"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 32, 32, 12)   324         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 32, 32, 12)   48          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 32, 32, 12)   0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 32, 32, 12)   1296        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 32, 32, 12)   0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 32, 32, 24)   0           conv2d[0][0]                     \n",
      "                                                                 dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32, 32, 24)   96          concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 32, 32, 24)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 32, 12)   2592        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 32, 32, 12)   0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 32, 32, 36)   0           concatenate[0][0]                \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 32, 36)   144         concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 32, 32, 36)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 32, 32, 12)   3888        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 32, 32, 12)   0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 32, 32, 48)   0           concatenate_1[0][0]              \n",
      "                                                                 dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 32, 48)   192         concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 32, 32, 48)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 32, 32, 12)   5184        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 32, 32, 12)   0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 32, 32, 60)   0           concatenate_2[0][0]              \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 32, 32, 60)   240         concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 32, 32, 60)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 32, 32, 12)   6480        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 32, 32, 12)   0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 32, 32, 72)   0           concatenate_3[0][0]              \n",
      "                                                                 dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 32, 32, 72)   288         concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 32, 32, 72)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 32, 32, 12)   7776        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 32, 32, 12)   0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 32, 32, 84)   0           concatenate_4[0][0]              \n",
      "                                                                 dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 32, 32, 84)   336         concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 32, 32, 84)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 12)   9072        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 32, 32, 12)   0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 32, 32, 96)   0           concatenate_5[0][0]              \n",
      "                                                                 dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 32, 32, 96)   384         concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 32, 32, 96)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 12)   10368       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 32, 32, 12)   0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 32, 32, 108)  0           concatenate_6[0][0]              \n",
      "                                                                 dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32, 32, 108)  432         concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 32, 32, 108)  0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 32, 12)   11664       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 32, 32, 12)   0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 32, 32, 120)  0           concatenate_7[0][0]              \n",
      "                                                                 dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 32, 32, 120)  480         concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 32, 32, 120)  0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 32, 32, 12)   12960       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 32, 32, 12)   0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 32, 32, 132)  0           concatenate_8[0][0]              \n",
      "                                                                 dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 32, 32, 132)  528         concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 32, 32, 132)  0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 32, 32, 12)   14256       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 32, 32, 12)   0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 32, 32, 144)  0           concatenate_9[0][0]              \n",
      "                                                                 dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 32, 32, 144)  576         concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 32, 32, 144)  0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 32, 32, 12)   15552       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 32, 32, 12)   0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 32, 32, 156)  0           concatenate_10[0][0]             \n",
      "                                                                 dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 32, 32, 156)  624         concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 32, 32, 156)  0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 32, 32, 6)    936         activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 32, 32, 6)    0           conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 16, 16, 6)    0           dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 16, 16, 6)    24          average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 16, 16, 6)    0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 16, 16, 12)   648         activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 16, 16, 12)   0           conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 16, 16, 18)   0           average_pooling2d[0][0]          \n",
      "                                                                 dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 16, 16, 18)   72          concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 16, 16, 18)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 16, 16, 12)   1944        activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 16, 16, 12)   0           conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 16, 16, 30)   0           concatenate_12[0][0]             \n",
      "                                                                 dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 16, 16, 30)   120         concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 16, 16, 30)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 16, 16, 12)   3240        activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 16, 16, 12)   0           conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 16, 16, 42)   0           concatenate_13[0][0]             \n",
      "                                                                 dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 16, 16, 42)   168         concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 16, 16, 42)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 16, 16, 12)   4536        activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 16, 16, 12)   0           conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 16, 16, 54)   0           concatenate_14[0][0]             \n",
      "                                                                 dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 16, 16, 54)   216         concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 16, 16, 54)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 16, 16, 12)   5832        activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 16, 16, 12)   0           conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 16, 16, 66)   0           concatenate_15[0][0]             \n",
      "                                                                 dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 16, 16, 66)   264         concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 16, 16, 66)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 16, 16, 12)   7128        activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 16, 16, 12)   0           conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)    (None, 16, 16, 78)   0           concatenate_16[0][0]             \n",
      "                                                                 dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 16, 16, 78)   312         concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 16, 16, 78)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 16, 16, 12)   8424        activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 16, 16, 12)   0           conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)    (None, 16, 16, 90)   0           concatenate_17[0][0]             \n",
      "                                                                 dropout_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 16, 16, 90)   360         concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 16, 16, 90)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 16, 16, 12)   9720        activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 16, 16, 12)   0           conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)    (None, 16, 16, 102)  0           concatenate_18[0][0]             \n",
      "                                                                 dropout_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 16, 16, 102)  408         concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 16, 16, 102)  0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 16, 16, 12)   11016       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 16, 16, 12)   0           conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_20 (Concatenate)    (None, 16, 16, 114)  0           concatenate_19[0][0]             \n",
      "                                                                 dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 16, 16, 114)  456         concatenate_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 16, 16, 114)  0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 16, 16, 12)   12312       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, 16, 16, 12)   0           conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_21 (Concatenate)    (None, 16, 16, 126)  0           concatenate_20[0][0]             \n",
      "                                                                 dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 16, 16, 126)  504         concatenate_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 16, 16, 126)  0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 16, 16, 12)   13608       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, 16, 16, 12)   0           conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_22 (Concatenate)    (None, 16, 16, 138)  0           concatenate_21[0][0]             \n",
      "                                                                 dropout_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 16, 16, 138)  552         concatenate_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 16, 16, 138)  0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 16, 16, 12)   14904       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, 16, 16, 12)   0           conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_23 (Concatenate)    (None, 16, 16, 150)  0           concatenate_22[0][0]             \n",
      "                                                                 dropout_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 16, 16, 150)  600         concatenate_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 16, 16, 150)  0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 16, 16, 6)    900         activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)            (None, 16, 16, 6)    0           conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 8, 8, 6)      0           dropout_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 8, 8, 6)      24          average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 8, 8, 6)      0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 8, 8, 12)     648         activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)            (None, 8, 8, 12)     0           conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_24 (Concatenate)    (None, 8, 8, 18)     0           average_pooling2d_1[0][0]        \n",
      "                                                                 dropout_26[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 8, 8, 18)     72          concatenate_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 8, 8, 18)     0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 8, 8, 12)     1944        activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)            (None, 8, 8, 12)     0           conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_25 (Concatenate)    (None, 8, 8, 30)     0           concatenate_24[0][0]             \n",
      "                                                                 dropout_27[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 8, 8, 30)     120         concatenate_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 8, 8, 30)     0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 8, 8, 12)     3240        activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_28 (Dropout)            (None, 8, 8, 12)     0           conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_26 (Concatenate)    (None, 8, 8, 42)     0           concatenate_25[0][0]             \n",
      "                                                                 dropout_28[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 8, 8, 42)     168         concatenate_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 8, 8, 42)     0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 8, 8, 12)     4536        activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_29 (Dropout)            (None, 8, 8, 12)     0           conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_27 (Concatenate)    (None, 8, 8, 54)     0           concatenate_26[0][0]             \n",
      "                                                                 dropout_29[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 8, 8, 54)     216         concatenate_27[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 8, 8, 54)     0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 8, 8, 12)     5832        activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_30 (Dropout)            (None, 8, 8, 12)     0           conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_28 (Concatenate)    (None, 8, 8, 66)     0           concatenate_27[0][0]             \n",
      "                                                                 dropout_30[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 8, 8, 66)     264         concatenate_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 8, 8, 66)     0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 8, 8, 12)     7128        activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_31 (Dropout)            (None, 8, 8, 12)     0           conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_29 (Concatenate)    (None, 8, 8, 78)     0           concatenate_28[0][0]             \n",
      "                                                                 dropout_31[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 8, 8, 78)     312         concatenate_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 8, 8, 78)     0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 8, 8, 12)     8424        activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_32 (Dropout)            (None, 8, 8, 12)     0           conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_30 (Concatenate)    (None, 8, 8, 90)     0           concatenate_29[0][0]             \n",
      "                                                                 dropout_32[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 8, 8, 90)     360         concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 8, 8, 90)     0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 8, 8, 12)     9720        activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_33 (Dropout)            (None, 8, 8, 12)     0           conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_31 (Concatenate)    (None, 8, 8, 102)    0           concatenate_30[0][0]             \n",
      "                                                                 dropout_33[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 8, 8, 102)    408         concatenate_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 8, 8, 102)    0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 8, 8, 12)     11016       activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_34 (Dropout)            (None, 8, 8, 12)     0           conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_32 (Concatenate)    (None, 8, 8, 114)    0           concatenate_31[0][0]             \n",
      "                                                                 dropout_34[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 8, 8, 114)    456         concatenate_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 8, 8, 114)    0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 8, 8, 12)     12312       activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_35 (Dropout)            (None, 8, 8, 12)     0           conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_33 (Concatenate)    (None, 8, 8, 126)    0           concatenate_32[0][0]             \n",
      "                                                                 dropout_35[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 8, 8, 126)    504         concatenate_33[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 8, 8, 126)    0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 8, 8, 12)     13608       activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_36 (Dropout)            (None, 8, 8, 12)     0           conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_34 (Concatenate)    (None, 8, 8, 138)    0           concatenate_33[0][0]             \n",
      "                                                                 dropout_36[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 8, 8, 138)    552         concatenate_34[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 8, 8, 138)    0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 8, 8, 12)     14904       activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)            (None, 8, 8, 12)     0           conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_35 (Concatenate)    (None, 8, 8, 150)    0           concatenate_34[0][0]             \n",
      "                                                                 dropout_37[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 8, 8, 150)    600         concatenate_35[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 8, 8, 150)    0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 8, 8, 6)      900         activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_38 (Dropout)            (None, 8, 8, 6)      0           conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 4, 4, 6)      0           dropout_38[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 4, 4, 6)      24          average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 4, 4, 6)      0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 4, 4, 12)     648         activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_39 (Dropout)            (None, 4, 4, 12)     0           conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_36 (Concatenate)    (None, 4, 4, 18)     0           average_pooling2d_2[0][0]        \n",
      "                                                                 dropout_39[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 4, 4, 18)     72          concatenate_36[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 4, 4, 18)     0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 4, 4, 12)     1944        activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_40 (Dropout)            (None, 4, 4, 12)     0           conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_37 (Concatenate)    (None, 4, 4, 30)     0           concatenate_36[0][0]             \n",
      "                                                                 dropout_40[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 4, 4, 30)     120         concatenate_37[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 4, 4, 30)     0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 4, 4, 12)     3240        activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_41 (Dropout)            (None, 4, 4, 12)     0           conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_38 (Concatenate)    (None, 4, 4, 42)     0           concatenate_37[0][0]             \n",
      "                                                                 dropout_41[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 4, 4, 42)     168         concatenate_38[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 4, 4, 42)     0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 4, 4, 12)     4536        activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_42 (Dropout)            (None, 4, 4, 12)     0           conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_39 (Concatenate)    (None, 4, 4, 54)     0           concatenate_38[0][0]             \n",
      "                                                                 dropout_42[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 4, 4, 54)     216         concatenate_39[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 4, 4, 54)     0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 4, 4, 12)     5832        activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_43 (Dropout)            (None, 4, 4, 12)     0           conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_40 (Concatenate)    (None, 4, 4, 66)     0           concatenate_39[0][0]             \n",
      "                                                                 dropout_43[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 4, 4, 66)     264         concatenate_40[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 4, 4, 66)     0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 4, 4, 12)     7128        activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_44 (Dropout)            (None, 4, 4, 12)     0           conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_41 (Concatenate)    (None, 4, 4, 78)     0           concatenate_40[0][0]             \n",
      "                                                                 dropout_44[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 4, 4, 78)     312         concatenate_41[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 4, 4, 78)     0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 4, 4, 12)     8424        activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_45 (Dropout)            (None, 4, 4, 12)     0           conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_42 (Concatenate)    (None, 4, 4, 90)     0           concatenate_41[0][0]             \n",
      "                                                                 dropout_45[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 4, 4, 90)     360         concatenate_42[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 4, 4, 90)     0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 4, 4, 12)     9720        activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_46 (Dropout)            (None, 4, 4, 12)     0           conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_43 (Concatenate)    (None, 4, 4, 102)    0           concatenate_42[0][0]             \n",
      "                                                                 dropout_46[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 4, 4, 102)    408         concatenate_43[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 4, 4, 102)    0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 4, 4, 12)     11016       activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_47 (Dropout)            (None, 4, 4, 12)     0           conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_44 (Concatenate)    (None, 4, 4, 114)    0           concatenate_43[0][0]             \n",
      "                                                                 dropout_47[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 4, 4, 114)    456         concatenate_44[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 4, 4, 114)    0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 4, 4, 12)     12312       activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_48 (Dropout)            (None, 4, 4, 12)     0           conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_45 (Concatenate)    (None, 4, 4, 126)    0           concatenate_44[0][0]             \n",
      "                                                                 dropout_48[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 4, 4, 126)    504         concatenate_45[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 4, 4, 126)    0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 4, 4, 12)     13608       activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_49 (Dropout)            (None, 4, 4, 12)     0           conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_46 (Concatenate)    (None, 4, 4, 138)    0           concatenate_45[0][0]             \n",
      "                                                                 dropout_49[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 4, 4, 138)    552         concatenate_46[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 4, 4, 138)    0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 4, 4, 12)     14904       activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_50 (Dropout)            (None, 4, 4, 12)     0           conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_47 (Concatenate)    (None, 4, 4, 150)    0           concatenate_46[0][0]             \n",
      "                                                                 dropout_50[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 4, 4, 150)    600         concatenate_47[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 2, 2, 150)    0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 600)          0           average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           6010        flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 406,630\n",
      "Trainable params: 398,362\n",
      "Non-trainable params: 8,268\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=[input], outputs=[output])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b4XOsW3ahSkL"
   },
   "outputs": [],
   "source": [
    "# determine Loss function and Optimizer\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 181
    },
    "colab_type": "code",
    "id": "crhGk7kEhXAz",
    "outputId": "3f64f92d-2a21-4901-8a5d-fbb220a9be57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "389/390 [============================>.] - ETA: 0s - loss: 1.7938 - acc: 0.3328\n",
      "Epoch 00001: val_acc improved from -inf to 0.43490, saving model to DenseNet_16.hdf5\n",
      "390/390 [==============================] - 65s 166ms/step - loss: 1.7932 - acc: 0.3328 - val_loss: 1.7548 - val_acc: 0.4349\n",
      "Epoch 2/50\n",
      "389/390 [============================>.] - ETA: 0s - loss: 1.4236 - acc: 0.4758\n",
      "Epoch 00002: val_acc improved from 0.43490 to 0.49639, saving model to DenseNet_16.hdf5\n",
      "390/390 [==============================] - 37s 95ms/step - loss: 1.4236 - acc: 0.4760 - val_loss: 1.6748 - val_acc: 0.4964\n",
      "Epoch 3/50\n",
      "389/390 [============================>.] - ETA: 0s - loss: 1.2525 - acc: 0.5437\n",
      "Epoch 00003: val_acc improved from 0.49639 to 0.54497, saving model to DenseNet_16.hdf5\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 1.2523 - acc: 0.5437 - val_loss: 1.6839 - val_acc: 0.5450\n",
      "Epoch 4/50\n",
      "389/390 [============================>.] - ETA: 0s - loss: 1.1507 - acc: 0.5850\n",
      "Epoch 00004: val_acc improved from 0.54497 to 0.54818, saving model to DenseNet_16.hdf5\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 1.1506 - acc: 0.5851 - val_loss: 1.5531 - val_acc: 0.5482\n",
      "Epoch 5/50\n",
      "389/390 [============================>.] - ETA: 0s - loss: 1.0754 - acc: 0.6102\n",
      "Epoch 00005: val_acc did not improve from 0.54818\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 1.0753 - acc: 0.6101 - val_loss: 2.0839 - val_acc: 0.5063\n",
      "Epoch 6/50\n",
      "389/390 [============================>.] - ETA: 0s - loss: 1.0159 - acc: 0.6341\n",
      "Epoch 00006: val_acc improved from 0.54818 to 0.59455, saving model to DenseNet_16.hdf5\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 1.0160 - acc: 0.6341 - val_loss: 1.2960 - val_acc: 0.5946\n",
      "Epoch 7/50\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.9675 - acc: 0.6518\n",
      "Epoch 00007: val_acc did not improve from 0.59455\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 0.9676 - acc: 0.6518 - val_loss: 1.3572 - val_acc: 0.5889\n",
      "Epoch 8/50\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.9178 - acc: 0.6711\n",
      "Epoch 00008: val_acc did not improve from 0.59455\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 0.9178 - acc: 0.6710 - val_loss: 1.5033 - val_acc: 0.5864\n",
      "Epoch 9/50\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.8721 - acc: 0.6903\n",
      "Epoch 00009: val_acc improved from 0.59455 to 0.62119, saving model to DenseNet_16.hdf5\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.8720 - acc: 0.6902 - val_loss: 1.4602 - val_acc: 0.6212\n",
      "Epoch 10/50\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.8403 - acc: 0.7002\n",
      "Epoch 00010: val_acc improved from 0.62119 to 0.66226, saving model to DenseNet_16.hdf5\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.8401 - acc: 0.7002 - val_loss: 1.1723 - val_acc: 0.6623\n",
      "Epoch 11/50\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.8065 - acc: 0.7137\n",
      "Epoch 00011: val_acc did not improve from 0.66226\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 0.8062 - acc: 0.7138 - val_loss: 1.2015 - val_acc: 0.6561\n",
      "Epoch 12/50\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.7822 - acc: 0.7238\n",
      "Epoch 00012: val_acc improved from 0.66226 to 0.71194, saving model to DenseNet_16.hdf5\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.7821 - acc: 0.7238 - val_loss: 0.9733 - val_acc: 0.7119\n",
      "Epoch 13/50\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.7516 - acc: 0.7352\n",
      "Epoch 00013: val_acc did not improve from 0.71194\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 0.7514 - acc: 0.7352 - val_loss: 1.0941 - val_acc: 0.6914\n",
      "Epoch 14/50\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.7388 - acc: 0.7399\n",
      "Epoch 00014: val_acc did not improve from 0.71194\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 0.7382 - acc: 0.7401 - val_loss: 1.2532 - val_acc: 0.6426\n",
      "Epoch 15/50\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.7151 - acc: 0.7471\n",
      "Epoch 00015: val_acc did not improve from 0.71194\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 0.7150 - acc: 0.7471 - val_loss: 1.2930 - val_acc: 0.6673\n",
      "Epoch 16/50\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.6936 - acc: 0.7570\n",
      "Epoch 00016: val_acc did not improve from 0.71194\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 0.6932 - acc: 0.7570 - val_loss: 0.9131 - val_acc: 0.7117\n",
      "Epoch 17/50\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.6783 - acc: 0.7617\n",
      "Epoch 00017: val_acc did not improve from 0.71194\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 0.6781 - acc: 0.7618 - val_loss: 1.0754 - val_acc: 0.6815\n",
      "Epoch 18/50\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.6668 - acc: 0.7664\n",
      "Epoch 00018: val_acc did not improve from 0.71194\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 0.6664 - acc: 0.7666 - val_loss: 1.0703 - val_acc: 0.7071\n",
      "Epoch 19/50\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.6549 - acc: 0.7705\n",
      "Epoch 00019: val_acc improved from 0.71194 to 0.71845, saving model to DenseNet_16.hdf5\n",
      "390/390 [==============================] - 37s 95ms/step - loss: 0.6546 - acc: 0.7706 - val_loss: 1.0067 - val_acc: 0.7184\n",
      "Epoch 20/50\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.6372 - acc: 0.7779\n",
      "Epoch 00020: val_acc improved from 0.71845 to 0.76152, saving model to DenseNet_16.hdf5\n",
      "390/390 [==============================] - 37s 95ms/step - loss: 0.6372 - acc: 0.7779 - val_loss: 0.7874 - val_acc: 0.7615\n",
      "Epoch 21/50\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.6319 - acc: 0.7798\n",
      "Epoch 00021: val_acc did not improve from 0.76152\n",
      "390/390 [==============================] - 36s 94ms/step - loss: 0.6317 - acc: 0.7799 - val_loss: 0.8913 - val_acc: 0.7361\n",
      "Epoch 22/50\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.6149 - acc: 0.7861\n",
      "Epoch 00022: val_acc improved from 0.76152 to 0.78976, saving model to DenseNet_16.hdf5\n",
      "390/390 [==============================] - 37s 95ms/step - loss: 0.6147 - acc: 0.7862 - val_loss: 0.6610 - val_acc: 0.7898\n",
      "Epoch 23/50\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.6080 - acc: 0.7894\n",
      "Epoch 00023: val_acc did not improve from 0.78976\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 0.6079 - acc: 0.7894 - val_loss: 0.7307 - val_acc: 0.7746\n",
      "Epoch 24/50\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5947 - acc: 0.7940\n",
      "Epoch 00024: val_acc did not improve from 0.78976\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 0.5950 - acc: 0.7939 - val_loss: 0.7214 - val_acc: 0.7791\n",
      "Epoch 25/50\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5846 - acc: 0.7974\n",
      "Epoch 00025: val_acc did not improve from 0.78976\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 0.5847 - acc: 0.7974 - val_loss: 0.7596 - val_acc: 0.7703\n",
      "Epoch 26/50\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5742 - acc: 0.8002\n",
      "Epoch 00026: val_acc did not improve from 0.78976\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 0.5743 - acc: 0.8001 - val_loss: 0.8210 - val_acc: 0.7657\n",
      "Epoch 27/50\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5679 - acc: 0.8025\n",
      "Epoch 00027: val_acc did not improve from 0.78976\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 0.5678 - acc: 0.8026 - val_loss: 0.7985 - val_acc: 0.7705\n",
      "Epoch 28/50\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5601 - acc: 0.8063\n",
      "Epoch 00028: val_acc improved from 0.78976 to 0.79447, saving model to DenseNet_16.hdf5\n",
      "390/390 [==============================] - 37s 95ms/step - loss: 0.5601 - acc: 0.8063 - val_loss: 0.6917 - val_acc: 0.7945\n",
      "Epoch 29/50\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5505 - acc: 0.8078\n",
      "Epoch 00029: val_acc did not improve from 0.79447\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 0.5508 - acc: 0.8078 - val_loss: 0.9169 - val_acc: 0.7388\n",
      "Epoch 30/50\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5399 - acc: 0.8128\n",
      "Epoch 00030: val_acc did not improve from 0.79447\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 0.5397 - acc: 0.8129 - val_loss: 0.8481 - val_acc: 0.7653\n",
      "Epoch 31/50\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5371 - acc: 0.8135\n",
      "Epoch 00031: val_acc did not improve from 0.79447\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 0.5369 - acc: 0.8135 - val_loss: 0.8680 - val_acc: 0.7575\n",
      "Epoch 32/50\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5265 - acc: 0.8165\n",
      "Epoch 00032: val_acc did not improve from 0.79447\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.5263 - acc: 0.8167 - val_loss: 0.7261 - val_acc: 0.7873\n",
      "Epoch 33/50\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5242 - acc: 0.8185\n",
      "Epoch 00033: val_acc improved from 0.79447 to 0.80389, saving model to DenseNet_16.hdf5\n",
      "390/390 [==============================] - 37s 95ms/step - loss: 0.5242 - acc: 0.8186 - val_loss: 0.6827 - val_acc: 0.8039\n",
      "Epoch 34/50\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5208 - acc: 0.8177\n",
      "Epoch 00034: val_acc did not improve from 0.80389\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 0.5205 - acc: 0.8179 - val_loss: 0.8245 - val_acc: 0.7784\n",
      "Epoch 35/50\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5105 - acc: 0.8234\n",
      "Epoch 00035: val_acc did not improve from 0.80389\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 0.5103 - acc: 0.8235 - val_loss: 0.6718 - val_acc: 0.7960\n",
      "Epoch 36/50\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5071 - acc: 0.8231\n",
      "Epoch 00036: val_acc did not improve from 0.80389\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 0.5069 - acc: 0.8231 - val_loss: 0.9070 - val_acc: 0.7491\n",
      "Epoch 37/50\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5041 - acc: 0.8259\n",
      "Epoch 00037: val_acc did not improve from 0.80389\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 0.5041 - acc: 0.8260 - val_loss: 1.0473 - val_acc: 0.7221\n",
      "Epoch 38/50\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.4945 - acc: 0.8278\n",
      "Epoch 00038: val_acc did not improve from 0.80389\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 0.4947 - acc: 0.8278 - val_loss: 1.0575 - val_acc: 0.7351\n",
      "Epoch 39/50\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.4875 - acc: 0.8299\n",
      "Epoch 00039: val_acc did not improve from 0.80389\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.4877 - acc: 0.8298 - val_loss: 0.7544 - val_acc: 0.7968\n",
      "Epoch 40/50\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.4860 - acc: 0.8312\n",
      "Epoch 00040: val_acc improved from 0.80389 to 0.81881, saving model to DenseNet_16.hdf5\n",
      "390/390 [==============================] - 37s 95ms/step - loss: 0.4862 - acc: 0.8311 - val_loss: 0.6414 - val_acc: 0.8188\n",
      "Epoch 41/50\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.4818 - acc: 0.8314\n",
      "Epoch 00041: val_acc did not improve from 0.81881\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 0.4820 - acc: 0.8315 - val_loss: 0.7037 - val_acc: 0.8046\n",
      "Epoch 42/50\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.4768 - acc: 0.8339\n",
      "Epoch 00042: val_acc did not improve from 0.81881\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 0.4766 - acc: 0.8340 - val_loss: 0.8789 - val_acc: 0.7635\n",
      "Epoch 43/50\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.4766 - acc: 0.8350\n",
      "Epoch 00043: val_acc did not improve from 0.81881\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 0.4767 - acc: 0.8350 - val_loss: 0.8186 - val_acc: 0.7753\n",
      "Epoch 44/50\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.4657 - acc: 0.8377\n",
      "Epoch 00044: val_acc did not improve from 0.81881\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 0.4655 - acc: 0.8378 - val_loss: 1.0109 - val_acc: 0.7492\n",
      "Epoch 45/50\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.4616 - acc: 0.8401\n",
      "Epoch 00045: val_acc improved from 0.81881 to 0.82522, saving model to DenseNet_16.hdf5\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.4616 - acc: 0.8401 - val_loss: 0.6228 - val_acc: 0.8252\n",
      "Epoch 46/50\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.4587 - acc: 0.8396\n",
      "Epoch 00046: val_acc did not improve from 0.82522\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 0.4586 - acc: 0.8396 - val_loss: 0.7549 - val_acc: 0.7930\n",
      "Epoch 47/50\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.4553 - acc: 0.8409\n",
      "Epoch 00047: val_acc did not improve from 0.82522\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 0.4558 - acc: 0.8408 - val_loss: 0.8775 - val_acc: 0.7699\n",
      "Epoch 48/50\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.4505 - acc: 0.8429\n",
      "Epoch 00048: val_acc did not improve from 0.82522\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 0.4508 - acc: 0.8427 - val_loss: 0.8072 - val_acc: 0.7839\n",
      "Epoch 49/50\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.4441 - acc: 0.8473\n",
      "Epoch 00049: val_acc did not improve from 0.82522\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 0.4442 - acc: 0.8473 - val_loss: 0.6424 - val_acc: 0.8241\n",
      "Epoch 50/50\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.4471 - acc: 0.8459\n",
      "Epoch 00050: val_acc did not improve from 0.82522\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 0.4472 - acc: 0.8458 - val_loss: 0.6353 - val_acc: 0.8220\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f81b9a61518>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint(\n",
    "    \"DenseNet_16.hdf5\",\n",
    "    monitor='val_acc',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    mode='max'\n",
    ")\n",
    "\n",
    "callbacks = [checkpoint]\n",
    "\n",
    "model.fit(\n",
    "    train_dataset,\n",
    "    epochs=epochs,\n",
    "    steps_per_epoch=50000//batch_size,\n",
    "    validation_data=test_dataset,\n",
    "    validation_steps=10000//batch_size,\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "ZcWydmIVhZGr",
    "outputId": "a0345aa5-79ff-4e56-eb94-50437b43c4fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/78 [==============================] - 3s 35ms/step - loss: 0.6228 - acc: 0.8252\n",
      "Test loss: 0.6227653450690783\n",
      "Test accuracy: 0.82522035\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "model.load_weights('DenseNet_16.hdf5')\n",
    "score = model.evaluate(\n",
    "    test_dataset,\n",
    "    steps=10000//batch_size,\n",
    "    verbose=1\n",
    ")\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ai-yZ2ED5AK1"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "files.download('DenseNet_16.hdf5')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Assignment_16.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
